#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯å’Œå¯è§†åŒ–è„šæœ¬ - å…¨é¢å±•ç¤ºæ¨¡å‹æ€§èƒ½å’Œæ ¸å¿ƒåˆ›æ–°

åŠŸèƒ½ï¼š
1. éªŒè¯é›†è¯„ä¼° - æ··æ·†çŸ©é˜µã€ROCæ›²çº¿ã€æ€§èƒ½æŒ‡æ ‡
2. CAVAæ¨¡å—å¯è§†åŒ– - éŸ³è§†é¢‘å¯¹é½ã€å»¶è¿Ÿä¼°è®¡ã€é—¨æ§æœºåˆ¶
3. MLPRæ¨¡å—å¯è§†åŒ– - æƒé‡åˆ†å¸ƒã€ç½®ä¿¡åº¦åˆ†æã€å†å²ç»Ÿè®¡
4. ç‰¹å¾ç©ºé—´å¯è§†åŒ– - t-SNEã€æ³¨æ„åŠ›å›¾ã€èåˆè¿‡ç¨‹
5. æ—¶åºåˆ†æ - é€å¸§ç‰¹å¾æ¼”åŒ–

ä½¿ç”¨æ–¹æ³•ï¼š
    python validate_and_visualize.py \
        --checkpoint runs/fixed_exp/checkpoints/best_f1.pth \
        --config selfsup_sota.yaml \
        --output ./visualizations \
        --num_samples 50
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import yaml
from tqdm import tqdm

# å¯è§†åŒ–åº“
import matplotlib

matplotlib.use('Agg')  # æ— GUIåç«¯
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.gridspec import GridSpec
from matplotlib.patches import Rectangle
import matplotlib.patches as mpatches

# ç§‘å­¦è®¡ç®—å’Œè¯„ä¼°
from sklearn.metrics import (
    confusion_matrix, classification_report,
    roc_curve, auc, roc_auc_score,
    accuracy_score, f1_score, precision_recall_curve
)
from sklearn.manifold import TSNE
from scipy.stats import entropy
from scipy.ndimage import gaussian_filter

# å¯¼å…¥æ¨¡å‹å’Œæ•°æ®é›†
from enhanced_detector import EnhancedAVTopDetector
from dataset import AVFromCSV, safe_collate_fn

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 150
plt.rcParams['savefig.dpi'] = 150
plt.rcParams['font.size'] = 10
plt.rcParams['figure.figsize'] = (12, 8)


# é…ç½®Windowså…¼å®¹çš„ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """é…ç½®ä¸­æ–‡å­—ä½“ï¼Œæ”¯æŒWindows/macOS/Linux"""
    import platform
    system = platform.system()

    if system == 'Windows':
        font_options = ['Microsoft YaHei', 'SimHei', 'SimSun', 'KaiTi']
    elif system == 'Darwin':
        font_options = ['PingFang SC', 'Heiti SC', 'STHeiti']
    else:
        font_options = ['WenQuanYi Micro Hei', 'Droid Sans Fallback', 'DejaVu Sans']

    try:
        import matplotlib.font_manager as fm
        available_fonts = set([f.name for f in fm.fontManager.ttflist])

        for font in font_options:
            if font in available_fonts:
                plt.rcParams['font.sans-serif'] = [font]
                plt.rcParams['axes.unicode_minus'] = False
                print(f"âœ“ ä½¿ç”¨å­—ä½“: {font}")
                return font
    except Exception as e:
        print(f"âš ï¸  å­—ä½“é…ç½®å¤±è´¥: {e}")

    plt.rcParams['axes.unicode_minus'] = False
    return None


setup_chinese_font()


class ModelVisualizer:
    """æ¨¡å‹å¯è§†åŒ–å™¨ - å…¨é¢å±•ç¤ºæ¨¡å‹è¡Œä¸ºå’Œæ€§èƒ½"""

    def __init__(
            self,
            model: nn.Module,
            dataloader: DataLoader,
            class_names: List[str],
            device: torch.device,
            output_dir: str
    ):
        self.model = model
        self.dataloader = dataloader
        self.class_names = class_names
        self.num_classes = len(class_names)
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / 'metrics').mkdir(exist_ok=True)
        (self.output_dir / 'cava').mkdir(exist_ok=True)
        (self.output_dir / 'mlpr').mkdir(exist_ok=True)
        (self.output_dir / 'features').mkdir(exist_ok=True)
        (self.output_dir / 'samples').mkdir(exist_ok=True)

        # æ”¶é›†çš„æ•°æ®
        self.predictions = []
        self.ground_truths = []
        self.probabilities = []
        self.features_data = {
            'video_features': [],
            'audio_features': [],
            'fusion_features': [],
            'cava_gates': [],
            'cava_delays': [],
            'attention_maps': [],
        }

        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")

    @torch.no_grad()
    def collect_predictions(self, num_samples: Optional[int] = None):
        """æ”¶é›†æ¨¡å‹é¢„æµ‹å’Œä¸­é—´ç‰¹å¾"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ç¬¬ä¸€æ­¥ï¼šæ”¶é›†é¢„æµ‹å’Œç‰¹å¾")
        print("=" * 60)

        self.model.eval()
        sample_count = 0

        pbar = tqdm(self.dataloader, desc="æ”¶é›†æ•°æ®")
        for batch in pbar:
            if isinstance(batch, (list, tuple)) and len(batch) >= 3:
                video, audio, labels = batch[:3]
            else:
                continue

            video = video.to(self.device)
            audio = audio.to(self.device)
            labels = labels.argmax(dim=1) if labels.ndim == 2 else labels

            # å‰å‘ä¼ æ’­ï¼ˆè·å–å®Œæ•´è¾“å‡ºï¼‰
            outputs = self.model(video, audio, return_aux=True)

            # æå–é¢„æµ‹
            if isinstance(outputs, dict):
                logits = outputs.get('clip_logits', list(outputs.values())[0])
            else:
                logits = outputs

            probs = F.softmax(logits, dim=1).cpu().numpy()
            preds = logits.argmax(dim=1).cpu().numpy()

            self.predictions.extend(preds)
            self.ground_truths.extend(labels.cpu().numpy())
            self.probabilities.extend(probs)

            # æ”¶é›†ä¸­é—´ç‰¹å¾
            if isinstance(outputs, dict):
                # è§†é¢‘ç‰¹å¾
                if 'video_proj' in outputs or 'video_emb' in outputs:
                    v_feat = outputs.get('video_proj', outputs.get('video_emb'))
                    if v_feat is not None:
                        self.features_data['video_features'].append(
                            v_feat.mean(dim=1).cpu().numpy()  # [B, D]
                        )

                # éŸ³é¢‘ç‰¹å¾
                if 'audio_aligned' in outputs or 'audio_emb' in outputs:
                    a_feat = outputs.get('audio_aligned', outputs.get('audio_emb'))
                    if a_feat is not None:
                        self.features_data['audio_features'].append(
                            a_feat.mean(dim=1).cpu().numpy()
                        )

                # èåˆç‰¹å¾
                if 'fusion_token' in outputs or 'fusion_out' in outputs:
                    f_feat = outputs.get('fusion_token', outputs.get('fusion_out'))
                    if f_feat is not None:
                        if f_feat.dim() > 2:
                            f_feat = f_feat.mean(dim=1)
                        self.features_data['fusion_features'].append(f_feat.cpu().numpy())

                # CAVAé—¨æ§
                if 'causal_gate' in outputs and outputs['causal_gate'] is not None:
                    gate = outputs['causal_gate']
                    if gate.dim() > 2:
                        gate = gate.mean(dim=1)  # [B, T] or [B]
                    self.features_data['cava_gates'].append(gate.cpu().numpy())

                # CAVAå»¶è¿Ÿ
                if 'delay_frames' in outputs and outputs['delay_frames'] is not None:
                    delay = outputs['delay_frames']
                    self.features_data['cava_delays'].append(delay.cpu().numpy())

            sample_count += len(labels)
            pbar.set_postfix({'samples': sample_count})

            if num_samples and sample_count >= num_samples:
                break

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        self.predictions = np.array(self.predictions)
        self.ground_truths = np.array(self.ground_truths)
        self.probabilities = np.array(self.probabilities)

        # åˆå¹¶ç‰¹å¾
        for key in ['video_features', 'audio_features', 'fusion_features',
                    'cava_gates', 'cava_delays']:
            if self.features_data[key]:
                self.features_data[key] = np.concatenate(self.features_data[key], axis=0)
            else:
                self.features_data[key] = None

        print(f"âœ… æ”¶é›†å®Œæˆ: {len(self.predictions)} ä¸ªæ ·æœ¬")
        print(f"   - é¢„æµ‹å½¢çŠ¶: {self.predictions.shape}")
        print(f"   - æ¦‚ç‡å½¢çŠ¶: {self.probabilities.shape}")
        if self.features_data['video_features'] is not None:
            print(f"   - è§†é¢‘ç‰¹å¾: {self.features_data['video_features'].shape}")
        if self.features_data['audio_features'] is not None:
            print(f"   - éŸ³é¢‘ç‰¹å¾: {self.features_data['audio_features'].shape}")
        if self.features_data['cava_gates'] is not None:
            print(f"   - CAVAé—¨æ§: {self.features_data['cava_gates'].shape}")
        if self.features_data['cava_delays'] is not None:
            print(f"   - CAVAå»¶è¿Ÿ: {self.features_data['cava_delays'].shape}")

    def visualize_basic_metrics(self):
        """1. åŸºç¡€æ€§èƒ½æŒ‡æ ‡å¯è§†åŒ–"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ç¬¬äºŒæ­¥ï¼šåŸºç¡€æ€§èƒ½æŒ‡æ ‡")
        print("=" * 60)

        # è®¡ç®—æŒ‡æ ‡
        acc = accuracy_score(self.ground_truths, self.predictions)
        f1_macro = f1_score(self.ground_truths, self.predictions, average='macro')
        f1_weighted = f1_score(self.ground_truths, self.predictions, average='weighted')

        # æ¯ç±»æŒ‡æ ‡
        report = classification_report(
            self.ground_truths, self.predictions,
            target_names=self.class_names,
            output_dict=True,
            zero_division=0
        )

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / 'metrics' / 'classification_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ•´ä½“å‡†ç¡®ç‡: {acc:.4f}")
        print(f"âœ… å®å¹³å‡F1: {f1_macro:.4f}")
        print(f"âœ… åŠ æƒF1: {f1_weighted:.4f}")

        # æ··æ·†çŸ©é˜µ
        self._plot_confusion_matrix()

        # ROCæ›²çº¿
        self._plot_roc_curves()

        # æ¯ç±»æ€§èƒ½æ¡å½¢å›¾
        self._plot_per_class_metrics(report)

        print(f"ğŸ’¾ æŒ‡æ ‡å·²ä¿å­˜åˆ°: {self.output_dir / 'metrics'}")

    def _plot_confusion_matrix(self):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(self.ground_truths, self.predictions)
        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        fig, axes = plt.subplots(1, 2, figsize=(20, 8))

        # åŸå§‹è®¡æ•°
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=self.class_names, yticklabels=self.class_names,
                    ax=axes[0], cbar_kws={'label': 'Count'})
        axes[0].set_title('æ··æ·†çŸ©é˜µ (è®¡æ•°)', fontsize=14, fontweight='bold')
        axes[0].set_ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        axes[0].set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)

        # å½’ä¸€åŒ–ç™¾åˆ†æ¯”
        sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='RdYlGn',
                    xticklabels=self.class_names, yticklabels=self.class_names,
                    ax=axes[1], cbar_kws={'label': 'Percentage'}, vmin=0, vmax=1)
        axes[1].set_title('æ··æ·†çŸ©é˜µ (å½’ä¸€åŒ–)', fontsize=14, fontweight='bold')
        axes[1].set_ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        axes[1].set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'metrics' / 'confusion_matrix.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ æ··æ·†çŸ©é˜µå·²ç”Ÿæˆ")

    def _plot_roc_curves(self):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        # è½¬æ¢ä¸ºone-hot
        y_true_oh = np.eye(self.num_classes)[self.ground_truths]

        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        axes = axes.flatten()

        aucs = []
        for i, class_name in enumerate(self.class_names):
            if i >= len(axes):
                break

            fpr, tpr, _ = roc_curve(y_true_oh[:, i], self.probabilities[:, i])
            roc_auc = auc(fpr, tpr)
            aucs.append(roc_auc)

            axes[i].plot(fpr, tpr, color='darkorange', lw=2,
                         label=f'AUC = {roc_auc:.3f}')
            axes[i].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
            axes[i].set_xlim([0.0, 1.0])
            axes[i].set_ylim([0.0, 1.05])
            axes[i].set_xlabel('å‡é˜³æ€§ç‡')
            axes[i].set_ylabel('çœŸé˜³æ€§ç‡')
            axes[i].set_title(f'{class_name}', fontweight='bold')
            axes[i].legend(loc="lower right")
            axes[i].grid(True, alpha=0.3)

        plt.suptitle(f'ROCæ›²çº¿ (å¹³å‡AUC = {np.mean(aucs):.3f})',
                     fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'metrics' / 'roc_curves.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ ROCæ›²çº¿å·²ç”Ÿæˆ")

    def _plot_per_class_metrics(self, report: Dict):
        """æ¯ç±»æ€§èƒ½æ¡å½¢å›¾"""
        classes = [c for c in self.class_names if c in report]
        precisions = [report[c]['precision'] for c in classes]
        recalls = [report[c]['recall'] for c in classes]
        f1s = [report[c]['f1-score'] for c in classes]
        supports = [report[c]['support'] for c in classes]

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        x = np.arange(len(classes))
        width = 0.25

        # Precision, Recall, F1å¯¹æ¯”
        axes[0, 0].bar(x - width, precisions, width, label='Precision', alpha=0.8)
        axes[0, 0].bar(x, recalls, width, label='Recall', alpha=0.8)
        axes[0, 0].bar(x + width, f1s, width, label='F1-Score', alpha=0.8)
        axes[0, 0].set_ylabel('åˆ†æ•°')
        axes[0, 0].set_title('æ¯ç±»æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”', fontweight='bold')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(classes, rotation=45, ha='right')
        axes[0, 0].legend()
        axes[0, 0].grid(axis='y', alpha=0.3)
        axes[0, 0].set_ylim([0, 1])

        # F1-Scoreæ’åº
        sorted_idx = np.argsort(f1s)
        axes[0, 1].barh(range(len(classes)), [f1s[i] for i in sorted_idx],
                        color=plt.cm.RdYlGn([f1s[i] for i in sorted_idx]))
        axes[0, 1].set_yticks(range(len(classes)))
        axes[0, 1].set_yticklabels([classes[i] for i in sorted_idx])
        axes[0, 1].set_xlabel('F1-Score')
        axes[0, 1].set_title('F1-Scoreæ’åº', fontweight='bold')
        axes[0, 1].grid(axis='x', alpha=0.3)
        axes[0, 1].set_xlim([0, 1])

        # æ ·æœ¬æ•°é‡
        axes[1, 0].bar(x, supports, alpha=0.7, color='steelblue')
        axes[1, 0].set_ylabel('æ ·æœ¬æ•°é‡')
        axes[1, 0].set_title('å„ç±»æ ·æœ¬åˆ†å¸ƒ', fontweight='bold')
        axes[1, 0].set_xticks(x)
        axes[1, 0].set_xticklabels(classes, rotation=45, ha='right')
        axes[1, 0].grid(axis='y', alpha=0.3)

        # åŠ æƒF1 vs æ ·æœ¬æ•°
        axes[1, 1].scatter(supports, f1s, s=100, alpha=0.6, c=f1s,
                           cmap='RdYlGn', vmin=0, vmax=1)
        for i, cls in enumerate(classes):
            axes[1, 1].annotate(cls, (supports[i], f1s[i]),
                                fontsize=8, alpha=0.7)
        axes[1, 1].set_xlabel('æ ·æœ¬æ•°é‡')
        axes[1, 1].set_ylabel('F1-Score')
        axes[1, 1].set_title('F1ä¸æ ·æœ¬æ•°å…³ç³»', fontweight='bold')
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'metrics' / 'per_class_metrics.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ æ¯ç±»æ€§èƒ½å›¾å·²ç”Ÿæˆ")

    def visualize_cava_module(self):
        """2. CAVAæ¨¡å—å¯è§†åŒ– - éŸ³è§†é¢‘å› æœå¯¹é½"""
        print("\n" + "=" * 60)
        print("ğŸ¯ ç¬¬ä¸‰æ­¥ï¼šCAVAæ¨¡å—å¯è§†åŒ–")
        print("=" * 60)

        if self.features_data['cava_gates'] is None:
            print("âš ï¸  CAVAé—¨æ§æ•°æ®ä¸å¯ç”¨ï¼Œè·³è¿‡")
            return

        # 1. é—¨æ§åˆ†å¸ƒåˆ†æ
        self._plot_cava_gate_distribution()

        # 2. å»¶è¿Ÿä¼°è®¡åˆ†æ
        if self.features_data['cava_delays'] is not None:
            self._plot_cava_delay_distribution()

        # 3. é—¨æ§ä¸é¢„æµ‹ç½®ä¿¡åº¦å…³ç³»
        self._plot_gate_confidence_relation()

        # 4. ä¸åŒç±»åˆ«çš„å¯¹é½æ¨¡å¼
        self._plot_alignment_patterns_per_class()

        print(f"ğŸ’¾ CAVAå¯è§†åŒ–å·²ä¿å­˜åˆ°: {self.output_dir / 'cava'}")

    def _plot_cava_gate_distribution(self):
        """CAVAé—¨æ§åˆ†å¸ƒ"""
        gates = self.features_data['cava_gates']

        if gates.ndim == 1:
            gates = gates.reshape(-1, 1)

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # æ•´ä½“åˆ†å¸ƒ
        axes[0, 0].hist(gates.flatten(), bins=50, alpha=0.7,
                        color='steelblue', edgecolor='black')
        axes[0, 0].axvline(gates.mean(), color='red', linestyle='--',
                           linewidth=2, label=f'Mean={gates.mean():.3f}')
        axes[0, 0].axvline(np.median(gates), color='green', linestyle='--',
                           linewidth=2, label=f'Median={np.median(gates):.3f}')
        axes[0, 0].set_xlabel('é—¨æ§å€¼')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].set_title('CAVAé—¨æ§åˆ†å¸ƒ', fontweight='bold')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # æŒ‰ç±»åˆ«åˆ†å¸ƒ
        unique_classes = np.unique(self.ground_truths)
        for cls in unique_classes[:6]:  # å‰6ç±»
            mask = self.ground_truths == cls
            cls_gates = gates[mask].flatten()
            axes[0, 1].hist(cls_gates, bins=30, alpha=0.5,
                            label=self.class_names[cls])
        axes[0, 1].set_xlabel('é—¨æ§å€¼')
        axes[0, 1].set_ylabel('é¢‘æ•°')
        axes[0, 1].set_title('å„ç±»åˆ«é—¨æ§åˆ†å¸ƒ', fontweight='bold')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # é—¨æ§vsé¢„æµ‹æ­£ç¡®æ€§
        correct = (self.predictions == self.ground_truths)
        gates_correct = gates[correct].flatten()
        gates_wrong = gates[~correct].flatten()

        axes[1, 0].hist([gates_correct, gates_wrong], bins=30,
                        label=['æ­£ç¡®é¢„æµ‹', 'é”™è¯¯é¢„æµ‹'],
                        alpha=0.7, color=['green', 'red'])
        axes[1, 0].set_xlabel('é—¨æ§å€¼')
        axes[1, 0].set_ylabel('é¢‘æ•°')
        axes[1, 0].set_title('é—¨æ§åˆ†å¸ƒï¼šæ­£ç¡®vsé”™è¯¯é¢„æµ‹', fontweight='bold')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # ç®±çº¿å›¾å¯¹æ¯”
        data_to_plot = [gates_correct, gates_wrong]
        bp = axes[1, 1].boxplot(data_to_plot, labels=['æ­£ç¡®', 'é”™è¯¯'],
                                patch_artist=True)
        for patch, color in zip(bp['boxes'], ['lightgreen', 'lightcoral']):
            patch.set_facecolor(color)
        axes[1, 1].set_ylabel('é—¨æ§å€¼')
        axes[1, 1].set_title('é—¨æ§åˆ†å¸ƒç®±çº¿å›¾', fontweight='bold')
        axes[1, 1].grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'cava' / 'gate_distribution.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ CAVAé—¨æ§åˆ†å¸ƒå·²ç”Ÿæˆ")

    def _plot_cava_delay_distribution(self):
        """CAVAå»¶è¿Ÿä¼°è®¡åˆ†å¸ƒ"""
        delays = self.features_data['cava_delays']

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # å»¶è¿Ÿåˆ†å¸ƒ
        axes[0, 0].hist(delays, bins=50, alpha=0.7, color='coral', edgecolor='black')
        axes[0, 0].axvline(delays.mean(), color='red', linestyle='--',
                           linewidth=2, label=f'Mean={delays.mean():.2f}')
        axes[0, 0].set_xlabel('å»¶è¿Ÿ (å¸§)')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].set_title('CAVAå»¶è¿Ÿä¼°è®¡åˆ†å¸ƒ', fontweight='bold')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # å»¶è¿Ÿvsé—¨æ§
        gates = self.features_data['cava_gates']
        if gates.ndim > 1:
            gates = gates.mean(axis=1)

        axes[0, 1].scatter(delays, gates, alpha=0.5, s=20)
        axes[0, 1].set_xlabel('å»¶è¿Ÿ (å¸§)')
        axes[0, 1].set_ylabel('å¹³å‡é—¨æ§å€¼')
        axes[0, 1].set_title('å»¶è¿Ÿ vs é—¨æ§å…³ç³»', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)

        # å„ç±»åˆ«å»¶è¿Ÿ
        unique_classes = np.unique(self.ground_truths)
        class_delays = [delays[self.ground_truths == cls] for cls in unique_classes]
        bp = axes[1, 0].boxplot(class_delays,
                                labels=[self.class_names[i] for i in unique_classes],
                                patch_artist=True)
        for patch in bp['boxes']:
            patch.set_facecolor('lightblue')
        axes[1, 0].set_xticklabels([self.class_names[i] for i in unique_classes],
                                   rotation=45, ha='right')
        axes[1, 0].set_ylabel('å»¶è¿Ÿ (å¸§)')
        axes[1, 0].set_title('å„ç±»åˆ«å»¶è¿Ÿåˆ†å¸ƒ', fontweight='bold')
        axes[1, 0].grid(axis='y', alpha=0.3)

        # å»¶è¿Ÿçƒ­å›¾
        delay_matrix = np.zeros((self.num_classes, 50))
        for cls in range(self.num_classes):
            mask = self.ground_truths == cls
            if mask.sum() > 0:
                hist, _ = np.histogram(delays[mask], bins=50, range=(delays.min(), delays.max()))
                delay_matrix[cls] = hist

        im = axes[1, 1].imshow(delay_matrix, aspect='auto', cmap='hot', interpolation='nearest')
        axes[1, 1].set_xlabel('å»¶è¿ŸåŒºé—´')
        axes[1, 1].set_ylabel('ç±»åˆ«')
        axes[1, 1].set_yticks(range(self.num_classes))
        axes[1, 1].set_yticklabels(self.class_names)
        axes[1, 1].set_title('ç±»åˆ«-å»¶è¿Ÿçƒ­å›¾', fontweight='bold')
        plt.colorbar(im, ax=axes[1, 1], label='æ ·æœ¬æ•°')

        plt.tight_layout()
        plt.savefig(self.output_dir / 'cava' / 'delay_distribution.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ CAVAå»¶è¿Ÿåˆ†å¸ƒå·²ç”Ÿæˆ")

    def _plot_gate_confidence_relation(self):
        """é—¨æ§ä¸é¢„æµ‹ç½®ä¿¡åº¦å…³ç³»"""
        gates = self.features_data['cava_gates']
        if gates.ndim > 1:
            gates = gates.mean(axis=1)

        # é¢„æµ‹ç½®ä¿¡åº¦
        max_probs = self.probabilities.max(axis=1)

        # é¢„æµ‹ç†µ
        pred_entropy = entropy(self.probabilities.T)

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # é—¨æ§ vs ç½®ä¿¡åº¦
        axes[0, 0].scatter(gates, max_probs, alpha=0.5, s=20, c=self.predictions,
                           cmap='tab20')
        axes[0, 0].set_xlabel('é—¨æ§å€¼')
        axes[0, 0].set_ylabel('é¢„æµ‹ç½®ä¿¡åº¦')
        axes[0, 0].set_title('é—¨æ§ vs é¢„æµ‹ç½®ä¿¡åº¦', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)

        # é—¨æ§ vs ç†µ
        axes[0, 1].scatter(gates, pred_entropy, alpha=0.5, s=20,
                           c=self.predictions, cmap='tab20')
        axes[0, 1].set_xlabel('é—¨æ§å€¼')
        axes[0, 1].set_ylabel('é¢„æµ‹ç†µ')
        axes[0, 1].set_title('é—¨æ§ vs é¢„æµ‹ä¸ç¡®å®šæ€§', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)

        # åˆ†ç»„åˆ†æï¼šé«˜é—¨æ§vsä½é—¨æ§
        gate_threshold = np.median(gates)
        high_gate_mask = gates > gate_threshold
        low_gate_mask = gates <= gate_threshold

        high_gate_conf = max_probs[high_gate_mask]
        low_gate_conf = max_probs[low_gate_mask]

        axes[1, 0].hist([high_gate_conf, low_gate_conf], bins=30,
                        label=[f'é«˜é—¨æ§(>{gate_threshold:.2f})',
                               f'ä½é—¨æ§(<={gate_threshold:.2f})'],
                        alpha=0.7, color=['green', 'orange'])
        axes[1, 0].set_xlabel('é¢„æµ‹ç½®ä¿¡åº¦')
        axes[1, 0].set_ylabel('é¢‘æ•°')
        axes[1, 0].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒï¼šé«˜é—¨æ§vsä½é—¨æ§', fontweight='bold')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # 2Då¯†åº¦å›¾
        from scipy.stats import gaussian_kde
        if len(gates) > 100:
            xy = np.vstack([gates, max_probs])
            z = gaussian_kde(xy)(xy)
            axes[1, 1].scatter(gates, max_probs, c=z, s=20, cmap='viridis', alpha=0.5)
            axes[1, 1].set_xlabel('é—¨æ§å€¼')
            axes[1, 1].set_ylabel('é¢„æµ‹ç½®ä¿¡åº¦')
            axes[1, 1].set_title('é—¨æ§-ç½®ä¿¡åº¦å¯†åº¦å›¾', fontweight='bold')
            plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1], label='å¯†åº¦')

        plt.tight_layout()
        plt.savefig(self.output_dir / 'cava' / 'gate_confidence_relation.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ é—¨æ§-ç½®ä¿¡åº¦å…³ç³»å›¾å·²ç”Ÿæˆ")

    def _plot_alignment_patterns_per_class(self):
        """å„ç±»åˆ«çš„å¯¹é½æ¨¡å¼"""
        gates = self.features_data['cava_gates']
        if gates.ndim == 1:
            gates = gates.reshape(-1, 1)

        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        axes = axes.flatten()

        for i, cls in enumerate(range(self.num_classes)):
            if i >= len(axes):
                break

            mask = self.ground_truths == cls
            cls_gates = gates[mask]

            if cls_gates.shape[1] > 1:
                # å¤šæ—¶é—´æ­¥ï¼šæ˜¾ç¤ºçƒ­å›¾
                im = axes[i].imshow(cls_gates[:min(50, len(cls_gates))].T,
                                    aspect='auto', cmap='RdYlGn', vmin=0, vmax=1)
                axes[i].set_xlabel('æ ·æœ¬')
                axes[i].set_ylabel('æ—¶é—´æ­¥')
                plt.colorbar(im, ax=axes[i], fraction=0.046)
            else:
                # å•å€¼ï¼šæ˜¾ç¤ºåˆ†å¸ƒ
                axes[i].hist(cls_gates.flatten(), bins=20, alpha=0.7,
                             color='steelblue', edgecolor='black')
                axes[i].set_xlabel('é—¨æ§å€¼')
                axes[i].set_ylabel('é¢‘æ•°')

            axes[i].set_title(f'{self.class_names[cls]}', fontweight='bold')
            axes[i].grid(True, alpha=0.3)

        plt.suptitle('å„ç±»åˆ«CAVAå¯¹é½æ¨¡å¼', fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'cava' / 'alignment_patterns.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ å„ç±»åˆ«å¯¹é½æ¨¡å¼å·²ç”Ÿæˆ")

    def visualize_feature_space(self):
        """3. ç‰¹å¾ç©ºé—´å¯è§†åŒ–"""
        print("\n" + "=" * 60)
        print("ğŸ—ºï¸  ç¬¬å››æ­¥ï¼šç‰¹å¾ç©ºé—´å¯è§†åŒ–")
        print("=" * 60)

        # t-SNEé™ç»´
        self._plot_tsne_visualization()

        # æ¨¡æ€èåˆåˆ†æ
        if (self.features_data['video_features'] is not None and
                self.features_data['audio_features'] is not None):
            self._plot_modality_fusion()

        # ç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µ
        self._plot_feature_similarity()

        print(f"ğŸ’¾ ç‰¹å¾ç©ºé—´å¯è§†åŒ–å·²ä¿å­˜åˆ°: {self.output_dir / 'features'}")

    def _plot_tsne_visualization(self):
        """t-SNEç‰¹å¾ç©ºé—´å¯è§†åŒ–"""
        # å°è¯•ä½¿ç”¨èåˆç‰¹å¾ï¼Œå›é€€åˆ°å…¶ä»–ç‰¹å¾
        features = None
        feature_name = ""

        if self.features_data['fusion_features'] is not None:
            features = self.features_data['fusion_features']
            feature_name = "Fusion"
        elif self.features_data['video_features'] is not None:
            features = self.features_data['video_features']
            feature_name = "Video"
        elif self.features_data['audio_features'] is not None:
            features = self.features_data['audio_features']
            feature_name = "Audio"
        else:
            print("  âš ï¸  æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾è¿›è¡Œt-SNEå¯è§†åŒ–")
            return

        print(f"  ä½¿ç”¨ {feature_name} ç‰¹å¾è¿›è¡Œt-SNE...")

        # t-SNEé™ç»´
        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features) - 1))
        features_2d = tsne.fit_transform(features)

        fig, axes = plt.subplots(2, 2, figsize=(16, 16))

        # æŒ‰çœŸå®æ ‡ç­¾ç€è‰²
        scatter1 = axes[0, 0].scatter(features_2d[:, 0], features_2d[:, 1],
                                      c=self.ground_truths, cmap='tab20',
                                      s=50, alpha=0.6, edgecolors='k', linewidth=0.5)
        axes[0, 0].set_title(f't-SNE: {feature_name}ç‰¹å¾ (çœŸå®æ ‡ç­¾)', fontweight='bold')
        axes[0, 0].set_xlabel('t-SNE ç»´åº¦ 1')
        axes[0, 0].set_ylabel('t-SNE ç»´åº¦ 2')
        legend1 = axes[0, 0].legend(*scatter1.legend_elements(),
                                    title="ç±»åˆ«", loc="best", ncol=2)
        axes[0, 0].add_artist(legend1)
        axes[0, 0].grid(True, alpha=0.3)

        # æŒ‰é¢„æµ‹æ ‡ç­¾ç€è‰²
        scatter2 = axes[0, 1].scatter(features_2d[:, 0], features_2d[:, 1],
                                      c=self.predictions, cmap='tab20',
                                      s=50, alpha=0.6, edgecolors='k', linewidth=0.5)
        axes[0, 1].set_title(f't-SNE: {feature_name}ç‰¹å¾ (é¢„æµ‹æ ‡ç­¾)', fontweight='bold')
        axes[0, 1].set_xlabel('t-SNE ç»´åº¦ 1')
        axes[0, 1].set_ylabel('t-SNE ç»´åº¦ 2')
        axes[0, 1].grid(True, alpha=0.3)

        # æŒ‰é¢„æµ‹ç½®ä¿¡åº¦ç€è‰²
        max_probs = self.probabilities.max(axis=1)
        scatter3 = axes[1, 0].scatter(features_2d[:, 0], features_2d[:, 1],
                                      c=max_probs, cmap='RdYlGn',
                                      s=50, alpha=0.6, edgecolors='k', linewidth=0.5,
                                      vmin=0, vmax=1)
        axes[1, 0].set_title('t-SNE: é¢„æµ‹ç½®ä¿¡åº¦', fontweight='bold')
        axes[1, 0].set_xlabel('t-SNE ç»´åº¦ 1')
        axes[1, 0].set_ylabel('t-SNE ç»´åº¦ 2')
        plt.colorbar(scatter3, ax=axes[1, 0], label='ç½®ä¿¡åº¦')
        axes[1, 0].grid(True, alpha=0.3)

        # æ ‡æ³¨é”™è¯¯é¢„æµ‹
        correct = (self.predictions == self.ground_truths)
        axes[1, 1].scatter(features_2d[correct, 0], features_2d[correct, 1],
                           c='green', s=30, alpha=0.3, label='æ­£ç¡®')
        axes[1, 1].scatter(features_2d[~correct, 0], features_2d[~correct, 1],
                           c='red', s=50, alpha=0.8, marker='x', label='é”™è¯¯')
        axes[1, 1].set_title('t-SNE: é¢„æµ‹æ­£ç¡®æ€§', fontweight='bold')
        axes[1, 1].set_xlabel('t-SNE ç»´åº¦ 1')
        axes[1, 1].set_ylabel('t-SNE ç»´åº¦ 2')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'features' / 'tsne_visualization.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ t-SNEå¯è§†åŒ–å·²ç”Ÿæˆ")

    def _plot_modality_fusion(self):
        """æ¨¡æ€èåˆåˆ†æ"""
        v_feat = self.features_data['video_features']
        a_feat = self.features_data['audio_features']

        # è®¡ç®—æ¨¡æ€é—´ç›¸ä¼¼åº¦
        v_norm = v_feat / (np.linalg.norm(v_feat, axis=1, keepdims=True) + 1e-8)
        a_norm = a_feat / (np.linalg.norm(a_feat, axis=1, keepdims=True) + 1e-8)
        similarity = np.sum(v_norm * a_norm, axis=1)

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # ç›¸ä¼¼åº¦åˆ†å¸ƒ
        axes[0, 0].hist(similarity, bins=50, alpha=0.7, color='purple', edgecolor='black')
        axes[0, 0].axvline(similarity.mean(), color='red', linestyle='--',
                           linewidth=2, label=f'Mean={similarity.mean():.3f}')
        axes[0, 0].set_xlabel('ä½™å¼¦ç›¸ä¼¼åº¦')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].set_title('éŸ³è§†é¢‘ç‰¹å¾ç›¸ä¼¼åº¦åˆ†å¸ƒ', fontweight='bold')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # ç›¸ä¼¼åº¦vsé¢„æµ‹ç½®ä¿¡åº¦
        max_probs = self.probabilities.max(axis=1)
        axes[0, 1].scatter(similarity, max_probs, alpha=0.5, s=20,
                           c=self.predictions, cmap='tab20')
        axes[0, 1].set_xlabel('æ¨¡æ€ç›¸ä¼¼åº¦')
        axes[0, 1].set_ylabel('é¢„æµ‹ç½®ä¿¡åº¦')
        axes[0, 1].set_title('æ¨¡æ€ç›¸ä¼¼åº¦ vs é¢„æµ‹ç½®ä¿¡åº¦', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)

        # å„ç±»åˆ«ç›¸ä¼¼åº¦
        class_similarities = [similarity[self.ground_truths == cls]
                              for cls in range(self.num_classes)]
        bp = axes[1, 0].boxplot(class_similarities,
                                labels=self.class_names,
                                patch_artist=True)
        for patch in bp['boxes']:
            patch.set_facecolor('lightblue')
        axes[1, 0].set_xticklabels(self.class_names, rotation=45, ha='right')
        axes[1, 0].set_ylabel('ç›¸ä¼¼åº¦')
        axes[1, 0].set_title('å„ç±»åˆ«æ¨¡æ€ç›¸ä¼¼åº¦', fontweight='bold')
        axes[1, 0].grid(axis='y', alpha=0.3)

        # æ­£ç¡®vsé”™è¯¯é¢„æµ‹çš„ç›¸ä¼¼åº¦
        correct = (self.predictions == self.ground_truths)
        axes[1, 1].hist([similarity[correct], similarity[~correct]],
                        bins=30, label=['æ­£ç¡®', 'é”™è¯¯'],
                        alpha=0.7, color=['green', 'red'])
        axes[1, 1].set_xlabel('æ¨¡æ€ç›¸ä¼¼åº¦')
        axes[1, 1].set_ylabel('é¢‘æ•°')
        axes[1, 1].set_title('æ¨¡æ€ç›¸ä¼¼åº¦ï¼šæ­£ç¡®vsé”™è¯¯é¢„æµ‹', fontweight='bold')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'features' / 'modality_fusion.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ æ¨¡æ€èåˆåˆ†æå·²ç”Ÿæˆ")

    def _plot_feature_similarity(self):
        """ç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µ"""
        # ä½¿ç”¨èåˆç‰¹å¾æˆ–è§†é¢‘ç‰¹å¾
        features = (self.features_data['fusion_features']
                    if self.features_data['fusion_features'] is not None
                    else self.features_data['video_features'])

        if features is None:
            return

        # è®¡ç®—ç±»ä¸­å¿ƒ
        class_centers = []
        for cls in range(self.num_classes):
            mask = self.ground_truths == cls
            if mask.sum() > 0:
                class_centers.append(features[mask].mean(axis=0))
            else:
                class_centers.append(np.zeros(features.shape[1]))
        class_centers = np.array(class_centers)

        # è®¡ç®—ç±»é—´ç›¸ä¼¼åº¦
        class_centers_norm = class_centers / (np.linalg.norm(class_centers, axis=1, keepdims=True) + 1e-8)
        similarity_matrix = np.dot(class_centers_norm, class_centers_norm.T)

        fig, axes = plt.subplots(1, 2, figsize=(18, 8))

        # ç›¸ä¼¼åº¦çŸ©é˜µ
        im1 = axes[0].imshow(similarity_matrix, cmap='RdBu_r', vmin=-1, vmax=1)
        axes[0].set_xticks(range(self.num_classes))
        axes[0].set_yticks(range(self.num_classes))
        axes[0].set_xticklabels(self.class_names, rotation=45, ha='right')
        axes[0].set_yticklabels(self.class_names)
        axes[0].set_title('ç±»é—´ç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µ', fontweight='bold')

        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                text = axes[0].text(j, i, f'{similarity_matrix[i, j]:.2f}',
                                    ha="center", va="center",
                                    color="white" if abs(similarity_matrix[i, j]) > 0.5 else "black",
                                    fontsize=8)

        plt.colorbar(im1, ax=axes[0], label='ä½™å¼¦ç›¸ä¼¼åº¦')

        # è·ç¦»çŸ©é˜µï¼ˆ1 - ç›¸ä¼¼åº¦ï¼‰
        distance_matrix = 1 - similarity_matrix
        np.fill_diagonal(distance_matrix, 0)

        im2 = axes[1].imshow(distance_matrix, cmap='YlOrRd', vmin=0, vmax=2)
        axes[1].set_xticks(range(self.num_classes))
        axes[1].set_yticks(range(self.num_classes))
        axes[1].set_xticklabels(self.class_names, rotation=45, ha='right')
        axes[1].set_yticklabels(self.class_names)
        axes[1].set_title('ç±»é—´ç‰¹å¾è·ç¦»çŸ©é˜µ', fontweight='bold')
        plt.colorbar(im2, ax=axes[1], label='è·ç¦» (1-ç›¸ä¼¼åº¦)')

        plt.tight_layout()
        plt.savefig(self.output_dir / 'features' / 'class_similarity_matrix.png',
                    dpi=150, bbox_inches='tight')
        plt.close()

        print("  âœ“ ç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µå·²ç”Ÿæˆ")

    def generate_summary_report(self):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“„ ç¬¬äº”æ­¥ï¼šç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
        print("=" * 60)

        acc = accuracy_score(self.ground_truths, self.predictions)
        f1_macro = f1_score(self.ground_truths, self.predictions, average='macro')

        report = {
            "overall_metrics": {
                "accuracy": float(acc),
                "f1_macro": float(f1_macro),
                "num_samples": len(self.predictions),
                "num_classes": self.num_classes,
            },
            "cava_statistics": {},
            "feature_statistics": {},
        }

        # CAVAç»Ÿè®¡
        if self.features_data['cava_gates'] is not None:
            gates = self.features_data['cava_gates']
            report["cava_statistics"]["gate_mean"] = float(gates.mean())
            report["cava_statistics"]["gate_std"] = float(gates.std())
            report["cava_statistics"]["gate_min"] = float(gates.min())
            report["cava_statistics"]["gate_max"] = float(gates.max())

        if self.features_data['cava_delays'] is not None:
            delays = self.features_data['cava_delays']
            report["cava_statistics"]["delay_mean"] = float(delays.mean())
            report["cava_statistics"]["delay_std"] = float(delays.std())

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / 'summary_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # åˆ›å»ºREADME
        self._create_readme()

    def _create_readme(self):
        """åˆ›å»ºREADMEæ–‡ä»¶"""
        readme_content = f"""# æ¨¡å‹éªŒè¯å’Œå¯è§†åŒ–ç»“æœ

## æ•´ä½“æ€§èƒ½

- **å‡†ç¡®ç‡**: {accuracy_score(self.ground_truths, self.predictions):.4f}
- **å®å¹³å‡F1**: {f1_score(self.ground_truths, self.predictions, average='macro'):.4f}
- **æ ·æœ¬æ•°é‡**: {len(self.predictions)}

## æ–‡ä»¶ç»“æ„

```
{self.output_dir.name}/
â”œâ”€â”€ metrics/                    # æ€§èƒ½æŒ‡æ ‡
â”‚   â”œâ”€â”€ confusion_matrix.png    # æ··æ·†çŸ©é˜µ
â”‚   â”œâ”€â”€ roc_curves.png          # ROCæ›²çº¿
â”‚   â”œâ”€â”€ per_class_metrics.png   # æ¯ç±»æ€§èƒ½
â”‚   â””â”€â”€ classification_report.json
â”‚
â”œâ”€â”€ cava/                       # CAVAæ¨¡å—å¯è§†åŒ–
â”‚   â”œâ”€â”€ gate_distribution.png   # é—¨æ§åˆ†å¸ƒ
â”‚   â”œâ”€â”€ delay_distribution.png  # å»¶è¿Ÿåˆ†å¸ƒ
â”‚   â”œâ”€â”€ gate_confidence_relation.png
â”‚   â””â”€â”€ alignment_patterns.png  # å¯¹é½æ¨¡å¼
â”‚
â”œâ”€â”€ features/                   # ç‰¹å¾ç©ºé—´
â”‚   â”œâ”€â”€ tsne_visualization.png  # t-SNEé™ç»´
â”‚   â”œâ”€â”€ modality_fusion.png     # æ¨¡æ€èåˆ
â”‚   â””â”€â”€ class_similarity_matrix.png
â”‚
â””â”€â”€ summary_report.json         # æ€»ç»“æŠ¥å‘Š
```

## æ ¸å¿ƒåˆ›æ–°å¯è§†åŒ–

### 1. CAVA (éŸ³è§†é¢‘å› æœå¯¹é½)
- é—¨æ§æœºåˆ¶åˆ†å¸ƒå’Œä½œç”¨
- å»¶è¿Ÿä¼°è®¡çš„å‡†ç¡®æ€§
- å¯¹é½è´¨é‡ä¸é¢„æµ‹æ€§èƒ½çš„å…³ç³»

### 2. ç‰¹å¾ç©ºé—´åˆ†æ
- å¤šæ¨¡æ€ç‰¹å¾èåˆæ•ˆæœ
- ç±»é—´å¯åˆ†æ€§
- t-SNEé™ç»´å¯è§†åŒ–

## ä½¿ç”¨æ–¹æ³•

1. æŸ¥çœ‹ `metrics/` äº†è§£æ•´ä½“æ€§èƒ½
2. æŸ¥çœ‹ `cava/` äº†è§£éŸ³è§†é¢‘å¯¹é½æ•ˆæœ
3. æŸ¥çœ‹ `features/` äº†è§£ç‰¹å¾å­¦ä¹ è´¨é‡

ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        readme_path = self.output_dir / 'README.md'
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)

        print(f"âœ… READMEå·²åˆ›å»º: {readme_path}")


def main():
    parser = argparse.ArgumentParser(description='æ¨¡å‹éªŒè¯å’Œå¯è§†åŒ–')
    parser.add_argument('--checkpoint', type=str, required=True,
                        help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--config', type=str, required=True,
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default='./visualizations',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--num_samples', type=int, default=None,
                        help='ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼ˆNone=å…¨éƒ¨ï¼‰')
    parser.add_argument('--batch_size', type=int, default=16,
                        help='æ‰¹å¤§å°')

    args = parser.parse_args()

    print("\n" + "=" * 60)
    print("ğŸ¨ æ¨¡å‹éªŒè¯å’Œå¯è§†åŒ–å·¥å…·")
    print("=" * 60)

    # åŠ è½½é…ç½®
    with open(args.config, 'r', encoding='utf-8') as f:
        cfg = yaml.safe_load(f)

    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {args.checkpoint}")
    model_cfg = cfg.get("model", {})
    model_cfg["num_classes"] = cfg["data"]["num_classes"]

    model = EnhancedAVTopDetector({
        "model": model_cfg,
        "fusion": model_cfg.get("fusion", {}),
        "cava": cfg.get("cava", {})
    }).to(device)

    checkpoint = torch.load(args.checkpoint, map_location=device)
    model.load_state_dict(checkpoint['state_dict'], strict=False)
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (Epoch {checkpoint.get('epoch', '?')})")

    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½éªŒè¯æ•°æ®...")
    data_cfg = cfg["data"]
    val_dataset = AVFromCSV(
        data_cfg["val_csv"],
        data_cfg.get("data_root"),
        data_cfg["num_classes"],
        data_cfg["class_names"],
        cfg.get("video", {}),
        cfg.get("audio", {}),
        is_unlabeled=False
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=0,
        collate_fn=safe_collate_fn
    )
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(val_dataset)} ä¸ªæ ·æœ¬")

    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = ModelVisualizer(
        model=model,
        dataloader=val_loader,
        class_names=data_cfg["class_names"],
        device=device,
        output_dir=args.output
    )

    # æ‰§è¡Œå¯è§†åŒ–æµç¨‹
    visualizer.collect_predictions(num_samples=args.num_samples)
    visualizer.visualize_basic_metrics()
    visualizer.visualize_cava_module()
    visualizer.visualize_feature_space()
    visualizer.generate_summary_report()

    print("\n" + "=" * 60)
    print("ğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output}")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    # æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥
    try:
        import pandas as pd
    except ImportError:
        import datetime


        class pd:
            class Timestamp:
                @staticmethod
                def now():
                    class FakeTimestamp:
                        def strftime(self, fmt):
                            return datetime.datetime.now().strftime(fmt)

                    return FakeTimestamp()

    main()